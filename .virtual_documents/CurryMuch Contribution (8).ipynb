import os
import glob as glob
import requests
import shutil

import pandas as pd
import numpy as np

#CV
import cv2

#modelling 
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras import Model, Sequential
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.utils import plot_model

#dataset preparation 
import sklearn
from sklearn.model_selection import train_test_split

#plotting 
import seaborn as sns
import matplotlib.pyplot as plt


# The notebook is supposed to run with TF 2.6.0
print(tf.__version__)
print(tf.test.is_gpu_available())
print(tf.config.list_physical_devices('GPU'))


get_ipython().run_line_magic("cd", " /home/jupyter/currymuch/datasets/")


get_ipython().getoutput("pip install opendatasets")
# !kaggle datasets download -d rkuo2000/uecfood100


import opendatasets as od
import pandas
 
od.download("https://www.kaggle.com/datasets/rkuo2000/uecfood100")


get_ipython().run_line_magic("cd", " /home/jupyter/currymuch/datasets/uecfood100/")


get_ipython().getoutput("python food_x_gen_bbox.py")


get_ipython().getoutput("python food100_split_for_yolo.py")


get_ipython().getoutput("python names2v5.py")


od.download("https://www.kaggle.com/datasets/rkuo2000/uecfood256")


get_ipython().getoutput("pip install aicrowd-cli > /dev/null")
get_ipython().getoutput("aicrowd login")


# List dataset for this challenge
get_ipython().getoutput("aicrowd dataset list -c food-recognition-benchmark-2022")


get_ipython().run_line_magic("cd", " /home/jupyter/currymuch/datasets/aicrowd")
# Download dataset
get_ipython().getoutput("aicrowd dataset download -c food-recognition-benchmark-2022 0 1 2 3 ")


get_ipython().run_line_magic("cd", " /home/jupyter/currymuch/datasets/aicrowd/")


#!mkdir -p data/ data/train data/val data/test
get_ipython().getoutput("cp *test* data/test && cd data/test && echo "Extracting test dataset" && tar -xvf *test* > /dev/null")
#!cp *val* data/val && cd data/val && echo "Extracting val dataset" &&  tar -xvf *val* > /dev/null
#!cp *train* data/train && cd data/train && echo "Extracting train dataset" &&  tar -xvf *train* > /dev/null


get_ipython().getoutput("conda install -y gdown")


get_ipython().run_line_magic("cd", " /home/jupyter")


#!gdown --version
#https://drive.google.com/file/d/1OVIb8WT0wWMkatPNi19LSCp8I6_T2N4r/view?usp=share_link
get_ipython().getoutput("gdown 1OVIb8WT0wWMkatPNi19LSCp8I6_T2N4r")


#https://pypi.org/project/gdrivefs/
# !sudo apt-get install -y build-essential python-dev
# !pip install gdrivefs
# !gdfstool auth_get_url
#!gdfstool auth_automatic
# !gdfstool auth_write "4/1AWgavdeM1vc0AUmSfsz2HY9BR6pmo5N6HQlBQc-8gbwj4iO6lNZtdCI2CeA"
# !gdfs -o allow_other default mnt/gdrivefs
# !ls mnt/gdrivefs


data = pd.read_csv('/home/jupyter/currymuch/food_all_data.csv')
data


len(data['label'].value_counts())


data['label'].value_counts()


dff = data[data['label'] == 'Bottle']
dff


labels = ['papadum', 'chicken', 'fish', 'egg', 'Doughnut','Sandwich', 'Hamburger', 'patties', 'roll', 'samosa', 'burger', 'pastry', 'cup_cake', 'fish_bun', 'cake_slice', 'cutlet']
dt = data[data['label'].isin(labels)]
dt


dt['label'] = dt['label'].replace(['Hamburger'], 'burger')


dt['label'].value_counts()
n_classes = len(dt['label'].value_counts()) 
n_classes


shuf = dt.sample(frac=1)
shuf.reset_index(drop=True, inplace=True)
shuf 


def write_csv(df, st):
  import os  
  #os.makedirs(f'/content/drive/MyDrive/L4S1/afr_train_test/', exist_ok=True)    
  df.to_csv(f'/home/jupyter/currymuch/{st}.csv')


def make_cols(csv):
    csv = csv.copy()
    #csv["valid"] = [True for i in range(len(csv))]
    csv["img_width"] = [0 for i in range(len(csv))]
    csv["img_height"] = [0 for i in range(len(csv))]
    return csv


shufcols = make_cols(shuf)
shufcols


write_csv(shufcols, 'shorteats3')


import zipfile
with zipfile.ZipFile('/home/jupyter/datasets/food_all.zip', 'r') as zip_ref:
    zip_ref.extractall('/home/jupyter/datasets/currymuch')


image_folder = '/home/jupyter/datasets/currymuch/food_all/'
def get_shape_img(df):
    df = df.copy()
    for row in range(len(df)):
        img = cv2.imread(image_folder+str(df['image'][row]))
        if img is None:
            print('could not read image!')
            return
        df["img_width"][row] = img.shape[1]
        df["img_height"][row] = img.shape[0]
    print('image shape added!')
    return df


shufcols = pd.read_csv('/home/jupyter/shorteats3.csv')
short_shape = get_shape_img(shufcols)
short_shape


def add_box_coords (csv):
  csv = csv.copy()
  csv["x"] = ((csv.xmin + csv.xmax)/2) / csv["img_width"]
  csv["y"] = ((csv.ymin + csv.ymax)/2) / csv["img_height"]

  csv["w"] = (csv.xmax - csv.xmin) / csv["img_width"]
  csv["h"] = (csv.ymax - csv.ymin) / csv["img_height"]

  csv.label = pd.Categorical(csv.label)
  csv['code'] = csv.label.cat.codes

  csv.sort_values(by=["image"], inplace=True)

  return csv


short_box = add_box_coords(short_shape)
short_box.reset_index(drop=True, inplace=True)
short_box


image_folder = '/home/jupyter/currymuch/datasets/food_all/'
output_folder = "/home/jupyter/currymuch/datasets/yolo_imgs"

def write_yolo_data(csv):
    csv = csv.copy()
    # write .names file
    names = {}
    for code in csv.code.unique():
        names[code] = csv[csv.code == code].iloc[0]["label"]
    with open(os.path.join(output_folder, "classes.names"), "w") as output:
        for i in range(len(names)):
            output.write(str(names[i]))
            output.write("\n")
            
 # write list of images file
    with open(os.path.join(output_folder, "train.txt"), "w") as output:
        for name in csv.image.unique():
            output.write("data/images/")
            output.write(name)
            output.write("\n")

    # write yolo data
    for name in csv.image.unique():
        # if copy_images:
        shutil.copy(os.path.join(image_folder, name), os.path.join(output_folder, name))
        with open(os.path.join(output_folder, os.path.splitext(name)[0]) + ".txt", "w") as output:
            for i, row in csv[csv.image == name].iterrows():
                output.write(str(row["code"]))
                output.write(" ")
                output.write(str(row["x"]))
                output.write(" ")
                output.write(str(row["y"]))
                output.write(" ")
                output.write(str(row["w"]))
                output.write(" ")
                output.write(str(row["h"]))
                output.write("\n")
                
    print('yolo data written to'+output_folder)


write_yolo_data(short_box)


# %cd '/home/jupyter/currymuch/datasets/shorteats'
# %ls -1 | wc -l 
#!find /home/jupyter/currymuch/datasets/yolo_imgs -name "*.names"


import zipfile

def zipdir(path, ziph):
    # ziph is zipfile handle
    for root, dirs, files in os.walk(path):
        for file in files:
            ziph.write(os.path.join(root, file), 
                       os.path.relpath(os.path.join(root, file), 
                                       os.path.join(path, '..')))

for n in range (1,3):
    with zipfile.ZipFile('/home/jupyter/currymuch/datasets/part/3_'+str(n)+'.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:
        zipdir('/home/jupyter/currymuch/datasets/part/yolo_imgs_3_'+str(n), zipf)


get_ipython().run_line_magic("cd", " /home/jupyter/currymuch/datasets/part/yolo_imgs_3")
get_ipython().run_line_magic("ls", " -1 | wc -l ")


# import os, os.path, shutil

# folder_path = "/home/jupyter/currymuch/datasets/part/yolo_imgs_3"
# new_dir = "/home/jupyter/currymuch/datasets/part/"

# images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]

# fcnt =0
# fol = 1
# for image in images:
#     fcnt = fcnt + 1
#     if fcnt <= 181:
#         folder_name = "yolo_imgs_3_"+str(fol)
#         new_path = os.path.join(new_dir, folder_name)
#         if not os.path.exists(new_path):
#             os.makedirs(new_path)
#         old_image_path = os.path.join(folder_path, image)
#         new_image_path = os.path.join(new_path, image)
#         shutil.copy(old_image_path, new_image_path)
#     else:
#         fol = fol + 1
#         fcnt = 0 


tr = int(shuf.shape[0]*0.7)
val = int(shuf.shape[0]*0.8)

past_train = shuf[:tr]
past_val = shuf[tr:val]
past_test = shuf[val:]

past_train.reset_index(drop=True, inplace=True)
past_val.reset_index(drop=True, inplace=True)
past_test.reset_index(drop=True, inplace=True)

past_val


write_csv(past_train,'train')
write_csv(past_val,'val')
write_csv(past_test,'test')


get_ipython().run_line_magic("ls", "")


get_ipython().getoutput("pip install roboflow")

get_ipython().run_line_magic("cd", " /home/jupyter/currymuch/datasets/")

from roboflow import Roboflow
rf = Roboflow(api_key="SXwDlxq023XK15DqysA5")
project = rf.workspace("afr").project("afr")
dataset = project.version(1).download("yolov5")


#!git clone https://github.com/ultralytics/yolov5  # clone
get_ipython().run_line_magic("cd", " yolov5")
get_ipython().run_line_magic("pip", " install -r requirements.txt  # install")


# import torch

# # Model
# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom

# # Images
# img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list

# # Inference
# results = model(img)

# # Results
# results.print()  # or .show(), .save(), .crop(), .pandas(), etc.


# !pip install roboflow


import torch

from IPython.display import Image, clear_output  # to display images
#from utils.downloads import attempt_download  # to download models/datasets

# clear_output()
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))


get_ipython().run_line_magic("cat", " /home/jupyter/yolov5/models/yolov5s.yaml")


from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))


get_ipython().run_cell_magic("writetemplate", " /home/jupyter/yolov5/models/custom_yolov5s.yaml", """
# parameters
nc: {num_classes}  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple

# anchors
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, BottleneckCSP, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, BottleneckCSP, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, BottleneckCSP, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, BottleneckCSP, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, BottleneckCSP, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]""")


get_ipython().run_line_magic("ls", "")


get_ipython().run_line_magic("cd", " /home/jupyter/yolov5")
get_ipython().getoutput("git pull")
get_ipython().run_line_magic("pip", " install -r requirements.txt ")


get_ipython().run_cell_magic("time", "", """%cd /home/jupyter/yolov5
!python train.py --img 416 --batch 16 --epochs 1000 --data /home/jupyter/currymuch/datasets/uecfood100-shorteats/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name yolov5s_results  --cache""")


get_ipython().getoutput("python val.py --data /home/jupyter/currymuch/datasets/uecfood100-shorteats/data.yaml --weights runs/train/yolov5s_results12/weights/best.pt --save-txt")


get_ipython().getoutput("python val.py --data {dataset.location}/data.yaml --task test --weights runs/train/yolov5s_results10/weights/best.pt --save-txt")


get_ipython().getoutput("python detect.py --weights runs/train/yolov5s_results11/weights/best.pt --img 416 --conf 0.1 --source /home/jupyter/roboflow_test --save-crop")
#--visualize


#display inference on ALL test images
import glob
from IPython.display import Image, display

for imageName in glob.glob('runs/detect/exp4/*.jpg'): #assuming JPG
    display(Image(filename=imageName))
    print("\n")


get_ipython().run_cell_magic("time", "", """%cd /home/jupyter/yolov5
!python train.py --img 640 --batch 16 --epochs 1000 --data /home/jupyter/currymuch/datasets/AFR-1/data.yaml --cfg ./models/yolov5m.yaml --weights yolov5m.pt --name yolov5s_chng_archi --cache --patience  300""")


get_ipython().getoutput("python val.py --data {dataset.location}/data.yaml --task test --weights runs/train/yolov5s_results10/weights/best.pt --save-txt")


occlusion_test_set("runs/train/yolov5s_results10/weights/best.pt", 640, 0.1, "/home/jupyter/roboflow_test")


disp_infer(10)


get_ipython().getoutput("pip install tensorboard")


get_ipython().run_line_magic("ls", " runs/train")


# Start tensorboard
# Launch after you have started training
# logs save in the folder "runs"
get_ipython().run_line_magic("load_ext", " tensorboard")
get_ipython().run_line_magic("tensorboard", " --logdir \"runs\"")


get_ipython().run_line_magic("ls", "")


from utils.plots import plot_results # plot results.txt as results.png
Image(filename='runs/train/yolov5s_results/results.png', width=1000)  # view results.png


def occlusion_test_set (ws, img_res, cnf, src):
    get_ipython().run_line_magic("cd", " /home/jupyter/yolov5")
    get_ipython().getoutput("python detect.py --weights {ws} --img {img_res} --conf {cnf} --source {src} --save-txt")


get_ipython().getoutput("python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.1 --source /home/jupyter/roboflow_test")


def disp_infer (exp_no):
    #display inference on ALL test images
    import glob
    from IPython.display import Image, display
    
    for imageName in glob.glob("runs/detect/exp"+ str(exp_no)+ "/*.jpg"): #assuming JPG
        display (Image(filename=imageName))
        print("\n")


# from utils.plots import plot_results
# plot_results('runs/train/yolov5s_results/results.csv')


#hyperparameter changer
def hyp_change ():
    #%%time
    get_ipython().run_line_magic("cd", " /home/jupyter/yolov5")
    img_size = [416, 640]
    b_size = [8, 16, 32]
    for iz in img_size:
        for bz in b_size:
            print(f"====================CONFIG: {iz}, {bz} ===============================")
            get_ipython().getoutput("python train.py --img {iz} --batch {bz} --epochs 3 --data /home/jupyter/currymuch/datasets/uecfood100-shorteats/data.yaml --cfg ./models/yolov5s.yaml --weights runs/train/yolov5s_results10/weights/best.pt --name yolov5s_hyper_results  --cache --freeze 10")


hyp_change()


get_ipython().getoutput("python train.py --img 416 --batch 16 --epochs 200 --data /home/jupyter/currymuch/datasets/AFR-1/data.yaml --cfg ./models/yolov5s.yaml --weights runs/train/yolov5s_results10/weights/best.pt --name yolov5s_evol_results --cache --patience 250 --freeze 10 --evolve 2")


get_ipython().run_line_magic("ls", " Food-Object-Detection--1/test")


get_ipython().getoutput("python segment/predict.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.1 --source /home/jupyter/roboflow_test")


pic = plt.imread('/home/jupyter/roboflow_test/0GYFO.jpg')/255  # dividing by 255 to bring the pixel values between 0 and 1
print(pic.shape)
plt.imshow(pic)


pic_n = pic.reshape(pic.shape[0]*pic.shape[1], pic.shape[2])
pic_n.shape


from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=4, random_state=0).fit(pic_n)
pic2show = kmeans.cluster_centers_[kmeans.labels_]


cluster_pic = pic2show.reshape(pic.shape[0], pic.shape[1], pic.shape[2])
plt.imshow(cluster_pic)


import cv2
import matplotlib.pyplot as plt
img = cv2.imread('/home/jupyter/roboflow_test/0GYFO.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    
dst = cv2.Canny(gray, 0, 150)
blured = cv2.blur(dst, (5,5), 0)    
MIN_CONTOUR_AREA=200
img_thresh = cv2.adaptiveThreshold(blured, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
Contours,imgContours = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
# for contour in Contours:
#     if cv2.contourArea(contour) > MIN_CONTOUR_AREA:
#         [X, Y, W, H] = cv2.boundingRect(contour)
#         box=cv2.rectangle(img, (X, Y), (X + W, Y + H), (0,0,255), 2)
#         cropped_image = img[Y:Y+H, X:X+W]
#         print([X,Y,W,H])
#         plt.imshow(cropped_image)
#         cv2.imwrite('xxx.png', cropped_image)
plt.imshow(img)


get_ipython().run_line_magic("ls", "")


# import os 

# name = "0GYFO"
# ext = ".jpg"
# imgname =  name + ext
# dyr = "/home/jupyter/yolov5/runs/detect/exp10/labels"
# imgdyr = "/home/jupyter/yolov5/runs/detect/exp10"

# img = cv2.imread(os.path.join(imgdyr,imgname))
# plt.imshow(img)


# import math

# # Using readlines()
# file1 = open(os.path.join(dyr, name) + '.txt', 'r')
# Lines = file1.readlines()

# boxes = []
# crops = []

# for i in range(0,len(Lines)):
#     coords = Lines[i].split()
#     X, Y, W, H = float(coords[1]), float(coords[2]), float(coords[3]), float(coords[4])
#     print(X,Y,W,H)
#     X, Y, W, H = math.floor(X*255),math.floor(X*255),math.floor(X*255),math.floor(X*255)
#     print(X,Y,W,H)
#     crops[i] = img[Y:Y + H, X:X + W]
#     plt.imshow(crops[i])

# # box=cv2.rectangle(img, (X, Y), (X + W, Y + H), (0,0,255), 2)
# # cropped_image = img[Y:Y + H, X:X + W]
# # print([X,Y,W,H])
# # plt.imshow(cropped_image)
# # cv2.imwrite(os.path.join(dyr,'xxx.png'), cropped_image)





# !pip install clearml

# %env CLEARML_WEB_HOST=https://app.clear.ml
# %env CLEARML_API_HOST=https://api.clear.ml
# %env CLEARML_FILES_HOST=https://files.clear.ml
# %env CLEARML_API_ACCESS_KEY=25XN7C9PKVM9WJVIW14O
# %env CLEARML_API_SECRET_KEY=5XHslNs4yqv9qGqkzSo9iPRinMRsQ9pb7oVrVxTU9nWIAYI3kx

# from clearml import Task
# task = Task.init(project_name="afr_contr", task_name="my task 1")



import wandb

wandb.init(project="test-project", entity="fit-afr")


get_ipython().getoutput("pip install wandb")


import wandb

wandb.init(project="interim-project", entity="fit-afr")


pip install comet_ml  # 1. install
export COMET_API_KEY=<Your API Key>  # 2. paste API key
python train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt  # 3. train
